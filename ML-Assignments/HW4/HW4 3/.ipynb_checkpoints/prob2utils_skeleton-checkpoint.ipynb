{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution routine for matrix factorization\n",
    "# CSCI 6140 HW4\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def grad_U(Ui, Yij, Vj, reg, eta):\n",
    "    \"\"\"\n",
    "    Takes as input Ui (the ith row of U), a training point Yij, the column\n",
    "    vector Vj (jth column of V^T), reg (the regularization parameter lambda),\n",
    "    and eta (the learning rate).\n",
    "\n",
    "    Returns the gradient of the regularized loss function with\n",
    "    respect to Ui multiplied by eta.\n",
    "    \"\"\"\n",
    "    \n",
    "    reg_term = reg * Ui\n",
    "    error_term = (Yij - (np.dot(Ui, Vj))) * Vj\n",
    "    gradient = reg_term - error_term \n",
    "    return eta * gradient\n",
    "\n",
    "\n",
    "def grad_V(Vj, Yij, Ui, reg, eta):\n",
    "    \"\"\"\n",
    "    Takes as input the column vector Vj (jth column of V^T), a training point Yij,\n",
    "    Ui (the ith row of U), reg (the regularization parameter lambda),\n",
    "    and eta (the learning rate).\n",
    "\n",
    "    Returns the gradient of the regularized loss function with\n",
    "    respect to Vj multiplied by eta.\n",
    "    \"\"\"\n",
    "    reg_term = reg * Vj\n",
    "    error_term = (Yij - (np.dot(Ui, Vj))) * Ui\n",
    "    gradient = reg_term - error_term \n",
    "    return eta * gradient\n",
    "\n",
    "def get_err(U, V, Y, reg=0.0):\n",
    "    \"\"\"\n",
    "    Takes as input a matrix Y of triples (i, j, Y_ij) where i is the index of a user,\n",
    "    j is the index of a movie, and Y_ij is user i's rating of movie j and\n",
    "    user/movie matrices U and V.\n",
    "\n",
    "    Returns the mean regularized squared-error of predictions made by\n",
    "    estimating Y_{ij} as the dot product of the ith row of U and the jth column of V^T.\n",
    "    \"\"\"\n",
    "    sqrd_error = 0\n",
    "    for i in range(len(Y)):\n",
    "        (i, j, Y_ij) = Y[i]\n",
    "        sqrd_error += 0.5 * (Y_ij - (np.dot(U[i - 1], V[j - 1])))**2\n",
    "    return sqrd_error / (len(Y))\n",
    "\n",
    "\n",
    "def train_model(M, N, K, eta, reg, Y, eps=0.0001, max_epochs=300):\n",
    "    \"\"\"\n",
    "    Given a training data matrix Y containing rows (i, j, Y_ij)\n",
    "    where Y_ij is user i's rating on movie j, learns an\n",
    "    M x K matrix U and N x K matrix V such that rating Y_ij is approximated\n",
    "    by (UV^T)_ij.\n",
    "\n",
    "    Uses a learning rate of <eta> and regularization of <reg>. Stops after\n",
    "    <max_epochs> epochs, or once the magnitude of the decrease in regularized\n",
    "    MSE between epochs is smaller than a fraction <eps> of the decrease in\n",
    "    MSE after the first epoch.\n",
    "\n",
    "    Returns a tuple (U, V, err) consisting of U, V, and the unregularized MSE\n",
    "    of the model.\n",
    "    \"\"\"\n",
    "    # U matrix initialized to random numbers\n",
    "    U = np.random.uniform(-0.5, 0.5, (M, K))\n",
    "    \n",
    "    # V matrix initialized to random numbers\n",
    "    V = np.random.uniform(-0.5, 0.5, (N, K))\n",
    "    \n",
    "    # MSE of the first epoch\n",
    "    curr_MSE_err = get_err(U, V, Y)\n",
    "    \n",
    "    # list of indices\n",
    "    indices = list(range(len(Y)))\n",
    "    \n",
    "    # on shuffling indices\n",
    "    shuffled_indices = np.random.permutation(indices)\n",
    "       \n",
    "    # computing new U and V using gradient descent    \n",
    "    for i in range(len(Y)):\n",
    "        i = shuffled_indices[i]\n",
    "        (i, j, Y_ij) = Y[i]\n",
    "        U[i - 1] = U[i - 1] - grad_U(U[i - 1], Y_ij, V[j - 1], reg, eta)\n",
    "        V[j - 1] = V[j - 1] - grad_V(V[j - 1], Y_ij, U[i - 1], reg, eta)\n",
    "        \n",
    "    # calculating MSE for new U and Y matrix generated    \n",
    "    new_MSE_err = get_err(U, V, Y)\n",
    "    difference = (current_MSE_err - new_MSE_err)\n",
    "    curr_MSE_err = new_MSE_err\n",
    "\n",
    "    epoch_cnt = 1\n",
    "    decrease = difference\n",
    "    while (epoch_cnt < max_epochs and decrease > eps * difference):\n",
    "        \n",
    "         # on shuffling indices\n",
    "        indices = list(range(len(Y)))\n",
    "        shuffled_indices = np.random.permutation(indices)\n",
    "        \n",
    "        # computing new U and V using gradient descent    \n",
    "        for i in range(len(Y)):\n",
    "            i = shuffled_indices[i]\n",
    "            (i, j, Y_ij) = Y[i]\n",
    "            U[i - 1] = U[i - 1] - grad_U(U[i - 1], Y_ij, V[j - 1], reg, eta)\n",
    "            V[j - 1] = V[j - 1] - grad_V(V[j - 1], Y_ij, U[i - 1], reg, eta)\n",
    "        \n",
    "        #calculating new MSE\n",
    "        new_MSE_err = get_err(U, V, Y)\n",
    "        decrease = curr_MSE - new_MSE_err\n",
    "        curr_MSE_err = new_MSE_err\n",
    "        epoch_cnt += 1\n",
    "        \n",
    "    return (U, V, curr_MSE_err)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
